{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9b0433",
   "metadata": {},
   "source": [
    "# Time-inVariant/Varying Multi-Variate Autoregressive Process Simulator/Estimator\n",
    "### TV/TiV MVAR sim/est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TiV_MVAR_simulator(A, x0, t, noise=None):\n",
    "    \"\"\"\n",
    "    Simulate a time-invariant multivariate autoregressive (MVAR) process.\n",
    "\n",
    "    This function generates data from an MVAR model with fixed coefficients\n",
    "    across time. The simulation allows optional input noise; if none is\n",
    "    provided, Gaussian noise is used by default.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray, shape (m, m, lags)\n",
    "        MVAR coefficient matrices for each lag, where `m` is the number of\n",
    "        variables and `lags` is the model order.\n",
    "    x0 : ndarray, shape (m, lags)\n",
    "        Initial conditions for the simulation. Each column corresponds to the\n",
    "        state of all variables at a lag time.\n",
    "    t : ndarray, shape (n,)\n",
    "        Array of time points. Determines the length of the simulated data.\n",
    "    noise : ndarray, shape (m, n), optional\n",
    "        Additive noise to the system. If None, standard normal Gaussian\n",
    "        noise is generated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : ndarray, shape (m, n)\n",
    "        Simulated MVAR data, where each row corresponds to a variable and each\n",
    "        column to a time point.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    n = t.shape[0]\n",
    "    m = x0.shape[0]\n",
    "    print(n)\n",
    "    Lag = x0.shape[1]\n",
    "\n",
    "    if noise is None:\n",
    "        noise = np.random.normal(loc=0, scale=1, size=(m, n))\n",
    "\n",
    "    x = np.zeros([m, n])\n",
    "    x[:, :Lag] = x0\n",
    "\n",
    "    for t_i in range(Lag, n):\n",
    "        x[:, t_i] = noise[:, t_i]\n",
    "\n",
    "        for p in range(Lag):\n",
    "            x[:, t_i] += A[:, :, p].dot(x[:, t_i-p-1])\n",
    "\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TiV_MVAR_estimator(data, MaxLagOrder, Order_selection_criterion=None, Order_selection_print=False):\n",
    "    \"\"\"\n",
    "    Estimate a time-invariant multivariate autoregressive (MVAR) model from data.\n",
    "\n",
    "    This function fits an MVAR model to multivariate time series data using\n",
    "    the specified maximum lag order. It supports automatic lag order selection\n",
    "    based on common information criteria.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (m, n)\n",
    "        Multivariate time series data, where `m` is the number of variables\n",
    "        (channels) and `n` is the number of time points.\n",
    "    MaxLagOrder : int\n",
    "        Maximum lag order to consider when fitting the MVAR model.\n",
    "    Order_selection_criterion : str, optional\n",
    "        Criterion for automatic lag order selection. Can be 'aic', 'bic', 'hqic',\n",
    "        or None to skip automatic selection. Default is None.\n",
    "    Order_selection_print : bool, optional\n",
    "        If True, prints the selected lag order during automatic selection.\n",
    "        Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A_est : ndarray, shape (m, m, lags)\n",
    "        Estimated MVAR coefficient matrices. The third dimension corresponds\n",
    "        to the lag order.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import statsmodels.tsa.api as sm\n",
    "\n",
    "    model = sm.VAR(data.T)\n",
    "\n",
    "    Order = MaxLagOrder\n",
    "    if Order_selection_criterion is not None:\n",
    "        if Order_selection_print:\n",
    "            print(f\"selected order = {model.select_order(MaxLagOrder).selected_orders}\")\n",
    "        Order = model.select_order(MaxLagOrder).selected_orders[Order_selection_criterion]\n",
    "\n",
    "    if Order == 0: Order = 1\n",
    "\n",
    "    results = model.fit(maxlags=Order, trend='c')\n",
    "\n",
    "    A_est = results.coefs\n",
    "    A_est = np.transpose(A_est, (1, 2, 0))  # Transpose to get shape (m, m, lags)\n",
    "\n",
    "\n",
    "    return A_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9037b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_MVAR_simulator(A, t_seg_edges, x0, t, noise=None):\n",
    "    \"\"\"\n",
    "    Simulate a time-varying multivariate autoregressive (TV-MVAR) process.\n",
    "\n",
    "    This function generates multivariate time series data from a TV-MVAR model,\n",
    "    where the coefficient matrices can change at specified time segments. \n",
    "    Optional additive noise can be provided; otherwise, Gaussian noise is used.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : list of ndarray, each with shape (m, m, lags)\n",
    "        List of MVAR coefficient matrices for each segment. Each entry corresponds\n",
    "        to a segment with its own lag-specific coefficients.\n",
    "    t_seg_edges : list of int or float\n",
    "        Time points (edges) where the MVAR coefficients change. The length\n",
    "        of this list should match the number of segments in `A`.\n",
    "    x0 : ndarray, shape (m, lags)\n",
    "        Initial conditions for the simulation. Each column corresponds to the\n",
    "        state of all variables at a lag time.\n",
    "    t : ndarray, shape (n,)\n",
    "        Array of time points. Determines the total length of the simulated data.\n",
    "    noise : ndarray, shape (m, n), optional\n",
    "        Additive noise for the system. If None, standard normal Gaussian noise\n",
    "        is generated. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : ndarray, shape (m, n)\n",
    "        Simulated TV-MVAR data, where each row corresponds to a variable\n",
    "        and each column to a time point.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    n = t.shape[0]\n",
    "    m = x0.shape[0]\n",
    "    Lag0 = x0.shape[1]\n",
    "\n",
    "    if noise is None: noise = np.random.normal(loc=0, scale=1, size=(m, n))\n",
    "\n",
    "    x = np.zeros([m, n])\n",
    "    x[:, :Lag0] = x0\n",
    "\n",
    "    seg_i = 0\n",
    "    for t_i in range(Lag0, n):\n",
    "        if t[t_i] >= t_seg_edges[seg_i]:   # ===== Updating A_i & lag when t changes =====\n",
    "            A_seg = A[seg_i]\n",
    "            Lag_seg = A_seg.shape[2]\n",
    "            seg_i += 1\n",
    "            \n",
    "        x[:, t_i] = noise[:, t_i]\n",
    "        for p in range(Lag_seg):\n",
    "            x[:, t_i] += A_seg[:, :, p].dot(x[:, t_i-p-1])\n",
    "\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c95855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sliding_Window_Order_selection_func(\n",
    "    data, MaxLagOrder, window_size, window_shift,\n",
    "    Order_selection_criterion='aic', Order_selection_print=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate the order of a multivariate autoregressive (MVAR) model using a sliding window approach.\n",
    "\n",
    "    This function applies a sliding window over multivariate time series data to\n",
    "    determine the optimal MVAR model order within each window, based on a specified\n",
    "    information criterion. The maximum order across all windows is returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (m, n)\n",
    "        Multivariate time series data, where `m` is the number of variables (channels)\n",
    "        and `n` is the number of time points.\n",
    "    MaxLagOrder : int\n",
    "        Maximum lag order to consider for MVAR model fitting.\n",
    "    window_size : int\n",
    "        Number of time points in each sliding window.\n",
    "    window_shift : int\n",
    "        Step size to shift the sliding window.\n",
    "    Order_selection_criterion : str, optional\n",
    "        Criterion for automatic order selection in each window. Options are 'aic',\n",
    "        'bic', 'hqic', or None to skip selection. Default is 'aic'.\n",
    "    Order_selection_print : bool, optional\n",
    "        If True, prints the selected order for each window. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Order : int\n",
    "        Estimated MVAR model order. It is the maximum order selected across all windows.\n",
    "        If no order greater than zero is found, returns 1.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    import statsmodels.tsa.api as sm\n",
    "\n",
    "    m, n = data.shape\n",
    "    Order_list = []\n",
    "\n",
    "    Order = 0\n",
    "    for start in range(0, n - window_size + 1, window_shift):\n",
    "        end = start + window_size\n",
    "        window_data = data[:, start:end]\n",
    "        \n",
    "        model = sm.VAR(window_data.T)\n",
    "        window_Order = model.select_order(MaxLagOrder).selected_orders[Order_selection_criterion]\n",
    "        Order_list += [window_Order]\n",
    "\n",
    "        if Order_selection_print:\n",
    "            print(f\"selected order = {window_Order} for window [{start}, {end})\")\n",
    "        \n",
    "        if window_Order>Order: Order = window_Order\n",
    "    \n",
    "    if Order == 0: Order = 1\n",
    "\n",
    "\n",
    "    return Order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_MVAR_estimator_sliding_window(\n",
    "    data, time, MaxLagOrder, window_size, window_shift,\n",
    "    t_ref_loc='mid', Order_selection_criterion=None, Order_selection_print=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate a time-varying multivariate autoregressive (TV-MVAR) model using a sliding window.\n",
    "\n",
    "    This function fits MVAR models to segments of multivariate time series data \n",
    "    defined by a sliding window. Coefficient matrices and their p-values are \n",
    "    returned for each window, providing a time-varying representation of the MVAR process.\n",
    "    The reference time for each window can be chosen as the start, middle, or end of the window.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (m, n)\n",
    "        Multivariate time series data, where `m` is the number of variables (channels)\n",
    "        and `n` is the number of time points.\n",
    "    time : ndarray, shape (n,)\n",
    "        Time points corresponding to each column of `data`.\n",
    "    MaxLagOrder : int\n",
    "        Maximum lag order for MVAR fitting.\n",
    "    window_size : int\n",
    "        Number of time points in each sliding window.\n",
    "    window_shift : int\n",
    "        Step size to shift the sliding window.\n",
    "    t_ref_loc : str, optional\n",
    "        Location of the reference time point for each window. Options are\n",
    "        'mid' (default), 'start', or 'end'.\n",
    "    Order_selection_criterion : str, optional\n",
    "        Criterion for automatic order selection within each window. Can be\n",
    "        'aic', 'bic', 'hqic', or None to skip order selection. Default is None.\n",
    "    Order_selection_print : bool, optional\n",
    "        If True, prints the selected order during order selection. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A_est : list of ndarray, each shape (m, m, lags)\n",
    "        List of estimated MVAR coefficient matrices for each window.\n",
    "    t_est : list of float\n",
    "        Reference time points corresponding to each estimated coefficient matrix.\n",
    "    pValues : list of ndarray, each shape (m, m, lags)\n",
    "        List of p-values associated with each coefficient matrix, indicating\n",
    "        statistical significance of the estimated coefficients.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    import statsmodels.tsa.api as sm\n",
    "\n",
    "    m, n     = data.shape\n",
    "    Order    = MaxLagOrder\n",
    "    A_est    = []\n",
    "    pValues  = []\n",
    "    t_est    = []\n",
    "\n",
    "    if Order_selection_criterion is not None:\n",
    "        Order = Sliding_Window_Order_selection_func(data, MaxLagOrder, window_size, window_shift, Order_selection_criterion, Order_selection_print)\n",
    "\n",
    "    for start in range(0, n - window_size + 1, window_shift):\n",
    "        end = start + window_size\n",
    "        window_data = data[:, start:end]\n",
    "\n",
    "        model = sm.VAR(window_data.T)\n",
    "        results = model.fit(maxlags=Order, trend='c')\n",
    "        A_est_basket = results.coefs\n",
    "        A_est_basket = np.transpose(A_est_basket, (1, 2, 0))\n",
    "\n",
    "        A_est.append(A_est_basket)\n",
    "        pValues.append(results.pvalues[1:,:].reshape([Order, m, m]).transpose((2, 1, 0)))\n",
    "\n",
    "        if t_ref_loc == 'mid'  : t_est.append((time[start] + time[end-1]) / 2)\n",
    "        if t_ref_loc == 'start': t_est.append(time[start])\n",
    "        if t_ref_loc == 'end'  : t_est.append(time[end-1])\n",
    "\n",
    "\n",
    "    return A_est, t_est, pValues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_MVAR_estimator_RLS(data, time, LagOrder=3, A0=None, P0=None, lambda_=0.90):\n",
    "    \"\"\"\n",
    "    Estimate a time-varying multivariate autoregressive (TV-MVAR) model using the recursive least squares (RLS) algorithm.\n",
    "\n",
    "    This function implements the RLS algorithm to estimate time-varying MVAR coefficients\n",
    "    from multivariate time series data. It supports both fixed and adaptive forgetting factors\n",
    "    and allows initialization of the coefficients and error covariance matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (m, n)\n",
    "        Multivariate time series data, where `m` is the number of variables (channels)\n",
    "        and `n` is the number of time points.\n",
    "    time : ndarray, shape (n,)\n",
    "        Time points corresponding to each column of `data`.\n",
    "    LagOrder : int, optional\n",
    "        Order of the MVAR model. Default is 3.\n",
    "    A0 : ndarray, shape (m, m*LagOrder), optional\n",
    "        Initial coefficient matrix for the RLS algorithm. Default is None (zeros).\n",
    "    P0 : ndarray, shape (m*LagOrder, m*LagOrder), optional\n",
    "        Initial covariance matrix for the RLS algorithm. Default is None (identity scaled by 1e5).\n",
    "    lambda_ : float or list/tuple of two floats, optional\n",
    "        Forgetting factor for the RLS algorithm. If a single float, a fixed forgetting factor\n",
    "        is used. If a list or tuple of two floats, an adaptive forgetting factor is applied\n",
    "        between the minimum and maximum values. Default is 0.90.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A_est : list of ndarray, each shape (m, m, LagOrder)\n",
    "        Estimated MVAR coefficient matrices for each time point.\n",
    "    t_est : list of float\n",
    "        Time points corresponding to each estimated coefficient matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    m, n = data.shape\n",
    "\n",
    "    adaptive_flag = False\n",
    "    if isinstance(lambda_, (list, tuple)) and len(lambda_) == 2 and all(isinstance(x, (int, float)) for x in lambda_):\n",
    "        adaptive_flag = True\n",
    "        lambda_min = min(lambda_)\n",
    "        lambda_max = max(lambda_)\n",
    "\n",
    "    if A0 is not None:\n",
    "        if A0.shape[0] != m or A0.shape[1] != m * LagOrder:\n",
    "            raise ValueError(f\"A0 must be of shape ({m}, {m * LagOrder})\")\n",
    "\n",
    "    if P0 is not None:\n",
    "        if P0.shape[0] != m * LagOrder or P0.shape[1] != m * LagOrder:\n",
    "            raise ValueError(f\"P0 must be of shape ({m * LagOrder}, {m * LagOrder})\")\n",
    "\n",
    "    \n",
    "    A = []; P = []\n",
    "    for _ in range(LagOrder):\n",
    "        A.append(np.zeros((m, m*LagOrder))  if A0 is None else A0)\n",
    "        P.append(np.eye(m * LagOrder) * 1e5 if P0 is None else P0)\n",
    "    phi = [[] for _ in range(LagOrder)]\n",
    "    K   = [[] for _ in range(LagOrder)]\n",
    "    e   = [[] for _ in range(LagOrder)]\n",
    "\n",
    "    A_est = [A[-1].reshape([m, m, LagOrder], order='F')]\n",
    "    t_est = [time[LagOrder-1]]\n",
    "    PValues = [np.zeros((m, m, LagOrder))]\n",
    "\n",
    "\n",
    "    for i in range(LagOrder, n, 1):\n",
    "        # print(f\"i = {i}\")\n",
    "        # ===== Computing vector of stacked past observations/lags =====\n",
    "        phi_i = []\n",
    "        for j in range(LagOrder):\n",
    "            phi_i.append(data[:, i-j-1].reshape([-1, 1]))\n",
    "        phi_i = np.concatenate(phi_i, axis=0)\n",
    "        phi.append(phi_i)\n",
    "\n",
    "        # ===== Adaptive forgetting factor for the first iteration =====\n",
    "        if adaptive_flag:\n",
    "            if i == LagOrder:\n",
    "                lambda_ = lambda_max\n",
    "            if i > LagOrder:\n",
    "                e_norm = np.linalg.norm( e[i-1] )\n",
    "                lambda_ = lambda_max - (lambda_max - lambda_min) * np.tanh(1e-3 * e_norm)\n",
    "\n",
    "        # ===== Computing Kalman gain K =====\n",
    "        K_i = P[i-1] @ phi[i] / (lambda_ + phi[i].T @ P[i-1] @ phi[i])\n",
    "        K.append(K_i)\n",
    "\n",
    "        # ===== Computing prediction error =====\n",
    "        x_i = A[i-1] @ phi[i]\n",
    "        e_i = data[:, i].reshape([-1,1]) - x_i\n",
    "        e.append(e_i)\n",
    "\n",
    "        # ===== Updating state estimate & error covariance =====\n",
    "        A_i = A[i-1] + e[i] @ K[i].T\n",
    "        A.append(A_i)\n",
    "\n",
    "        P_i = (P[i-1] - K[i] @ phi[i].T @ P[i-1]) / lambda_\n",
    "        # === Joseph-stabilized form:\n",
    "        # I = np.eye(m * LagOrder)\n",
    "        # P_i = (I - K[i] @ phi[i].T) @ P[i-1] @ (I - K[i] @ phi[i].T).T\n",
    "\n",
    "        P.append(P_i)\n",
    "\n",
    "        A_est.append(A[i].reshape([m, m, LagOrder], order='F'))\n",
    "        t_est.append(time[i])\n",
    "\n",
    "\n",
    "        # PValues_i = np.zeros((m, m * LagOrder))\n",
    "        # for ch in range(m):\n",
    "        #     A_ch = A[i][ch, :]\n",
    "        #     sigma2 = e[i][ch]**2\n",
    "        #     SE = np.sqrt(sigma2 * np.diag(P[i]))\n",
    "\n",
    "        #     Z = A_ch / SE\n",
    "        #     PValues_i[ch, :] = 2 * (1 - norm.cdf(abs(Z)))\n",
    "\n",
    "        # PValues += [PValues_i.reshape([m, m, LagOrder], order='F')]\n",
    "\n",
    "\n",
    "\n",
    "    return A_est, t_est\n",
    "    # return A_est, t_est, PValues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00febfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_MVAR_estimator_KF(\n",
    "    data, time, LagOrder, A0=None, P0=None, F=None, R=None, Q0=None,\n",
    "    LAMBDA=None, smoothing=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate a time-varying multivariate autoregressive (TV-MVAR) model using the Kalman filter.\n",
    "\n",
    "    This function applies the Kalman filter to estimate MVAR coefficients from\n",
    "    multivariate time series data. It supports optional smoothing, customizable\n",
    "    initial conditions, and process/measurement noise specifications.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (m, n)\n",
    "        Multivariate time series data, where `m` is the number of variables (channels)\n",
    "        and `n` is the number of time points.\n",
    "    time : ndarray, shape (n,)\n",
    "        Time points corresponding to each column of `data`.\n",
    "    LagOrder : int\n",
    "        Order of the MVAR model.\n",
    "    A0 : ndarray, shape (m, m*LagOrder), optional\n",
    "        Initial coefficient matrix for the Kalman filter. Default is zeros.\n",
    "    P0 : ndarray, shape (d, d), optional\n",
    "        Initial covariance matrix for the state estimate, with d = m*m*LagOrder.\n",
    "        Default is identity scaled by 1e5.\n",
    "    F : ndarray, shape (d, d), optional\n",
    "        State transition matrix. Default is identity.\n",
    "    R : ndarray, shape (m, m), optional\n",
    "        Measurement noise covariance matrix. Default is identity scaled by 1e2.\n",
    "    Q0 : ndarray, shape (d, d), optional\n",
    "        Initial process noise covariance matrix. Default is identity scaled by 1e-5.\n",
    "    LAMBDA : ndarray, shape (d, d), optional\n",
    "        Smoothing factors for the Kalman filter. Default is 0.5 * identity.\n",
    "    smoothing : bool, optional\n",
    "        If True, applies backward smoothing to refine coefficient estimates. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A_est : list of ndarray, each shape (m, m, LagOrder)\n",
    "        Estimated MVAR coefficient matrices for each time point. If `smoothing=True`,\n",
    "        these are smoothed estimates.\n",
    "    t_est : list of float\n",
    "        Time points corresponding to each estimated coefficient matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    m, n = data.shape\n",
    "    d = m*m*LagOrder\n",
    "\n",
    "    if A0 is not None:\n",
    "        if A0.shape[0] != m or A0.shape[1] != m * LagOrder:\n",
    "            raise ValueError(f\"A0 must be of shape ({m}, {m * LagOrder})\")\n",
    "    elif A0 is None: A0 = np.zeros([m, m * LagOrder])\n",
    "\n",
    "    if P0 is not None:\n",
    "        if P0.shape[0] != d or P0.shape[1] != d:\n",
    "            raise ValueError(f\"P0 must be of shape ({d}, {d})\")\n",
    "    elif P0 is None: P0 = np.eye(d) * 1e5\n",
    "\n",
    "    if F is not None:\n",
    "        if F.shape[0] != d or F.shape[1] != d:\n",
    "            raise ValueError(f\"F must be of shape ({d}, {d})\")\n",
    "    elif F is None: F = np.eye(d)\n",
    "\n",
    "    if R is not None:\n",
    "        if R.shape[0] != m or R.shape[1] != m:\n",
    "            raise ValueError(f\"R must be of shape ({m}, {m})\")\n",
    "    elif R is None: R = np.eye(m) * 1e2\n",
    "\n",
    "    if LAMBDA is not None:\n",
    "        if LAMBDA.shape[0] != d or LAMBDA.shape[1] != d:\n",
    "            raise ValueError(f\"LAMBDA must be of shape ({d}, {d})\")\n",
    "    elif LAMBDA is None: LAMBDA = np.eye(d) * 0.5\n",
    "\n",
    "    if Q0 is not None:\n",
    "        if Q0.shape[0] != d or Q0.shape[1] != d:\n",
    "            raise ValueError(f\"Q0 must be of shape ({d}, {d})\")\n",
    "    elif Q0 is None: Q0 = np.eye(d) * 1e-5\n",
    "\n",
    "\n",
    "    GAMMA = []; P = []; Q = []\n",
    "    for _ in range(LagOrder):\n",
    "        GAMMA.append(A0.reshape([-1, 1], order='F'))\n",
    "        P.append(P0)\n",
    "        Q.append(Q0)\n",
    "    Phi = [[] for _ in range(LagOrder)]\n",
    "    H   = [[] for _ in range(LagOrder)]\n",
    "    e   = [[] for _ in range(LagOrder)]\n",
    "    S   = [[] for _ in range(LagOrder)]\n",
    "    K   = [[] for _ in range(LagOrder)]\n",
    "\n",
    "    A_est = [GAMMA[-1].reshape([m, m, LagOrder], order='F')]\n",
    "    t_est = [time[LagOrder-1]]\n",
    "\n",
    "\n",
    "    for i in range(LagOrder, n):\n",
    "        # print(f\"i={i}\")\n",
    "        # ===== Computing vector of stacked past observations/lags =====\n",
    "        Phi_i = []\n",
    "        for j in range(LagOrder):\n",
    "            Phi_i.append(data[:, i-j-1].reshape([-1, 1]))\n",
    "        Phi_i = np.concatenate(Phi_i, axis=0)\n",
    "        Phi.append(Phi_i)\n",
    "\n",
    "        H_i = np.kron(Phi[i].T, np.eye(m))\n",
    "        H.append(H_i)\n",
    "\n",
    "        # ===== Computing prediction error =====\n",
    "        x_i = H[i] @ GAMMA[i-1]\n",
    "        e_i = data[:, i].reshape([-1,1]) - x_i\n",
    "        e.append(e_i)\n",
    "\n",
    "        S_i = H[i] @ P[i-1] @ H[i].T + R\n",
    "        S.append(S_i)\n",
    "\n",
    "        # ===== Computing Kalman gain K =====\n",
    "        K_i = P[i-1] @ H[i].T @ np.linalg.inv(S_i)\n",
    "        K.append(K_i)\n",
    "\n",
    "        # ===== Updating state estimate & error covariance =====\n",
    "        GAMMA_i = F @ GAMMA[i-1] + K[i] @ e[i]\n",
    "        GAMMA.append(GAMMA_i)\n",
    "\n",
    "        Q_i = LAMBDA @ Q[i-1] + (np.eye(d) - LAMBDA) * np.linalg.norm(e[i])**2\n",
    "        Q.append(Q_i)\n",
    "\n",
    "        P_i = (np.eye(d) - K[i] @ H[i]) @ P[i-1] + Q[i]\n",
    "        P.append(P_i)\n",
    "\n",
    "        A_est.append(GAMMA[i].reshape([m, m, LagOrder], order='F'))\n",
    "        t_est.append(time[i])\n",
    "\n",
    "\n",
    "    if smoothing:\n",
    "        # ===== Backward smoothing =====\n",
    "        GAMMA_smooth = np.zeros(shape=[m*m*LagOrder, len(A_est)])\n",
    "\n",
    "        for i in range(len(A_est)-3, -1, -1):\n",
    "            GAMMA_i = A_est[i].reshape([-1, 1], order='F')\n",
    "            W_i = P[i+LagOrder] @ np.linalg.inv( P[i+1+LagOrder] + Q[i+1+LagOrder] )\n",
    "            GAMMA_smooth[:,i] = ( GAMMA_i + W_i @ (GAMMA_smooth[:,i+1].reshape([-1, 1]) - GAMMA_i) ).flatten()\n",
    "\n",
    "        A_est_smooth = []\n",
    "        for i in range(len(A_est)):\n",
    "            A_est_smooth.append(GAMMA_smooth[:,i].reshape([m, m, LagOrder], order='F'))\n",
    "\n",
    "        A_est = A_est_smooth\n",
    "    \n",
    "    return A_est, t_est\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66806c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_MVAR_estimator_MultipleBasisExpansion(data, time, BasisLib, LagOrder):\n",
    "    \"\"\"\n",
    "    Estimate time-varying multivariate autoregressive (TV-MVAR) coefficients using multiple basis expansion.\n",
    "\n",
    "    This function models TV-MVAR coefficients as a linear combination of predefined\n",
    "    basis functions. The coefficients for each basis function are estimated using\n",
    "    least squares, and the time-varying MVAR matrices are reconstructed for each\n",
    "    time point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (m, n)\n",
    "        Multivariate time series data, where `m` is the number of variables (channels)\n",
    "        and `n` is the number of time points.\n",
    "    time : ndarray, shape (n,)\n",
    "        Time points corresponding to each column of `data`.\n",
    "    BasisLib : ndarray, shape (V, n)\n",
    "        Library of basis functions used to model time-varying coefficients, where\n",
    "        `V` is the number of basis functions and `n` is the number of time points.\n",
    "    LagOrder : int\n",
    "        Number of lags to include in the MVAR model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A_est : list of ndarray, each shape (m, m, LagOrder)\n",
    "        Estimated TV-MVAR coefficient matrices for each time point.\n",
    "    t_est : list of float\n",
    "        Time points corresponding to each estimated coefficient matrix.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    import scipy as sp\n",
    "    # from sklearn.linear_model import Ridge\n",
    "    \n",
    "    m,n = data.shape\n",
    "    Basis_num = BasisLib.shape[0]\n",
    "\n",
    "    # ======= Prepare the data for least squares estimation =======\n",
    "    Y = []; X = []\n",
    "    for i in range(LagOrder, n):\n",
    "        Y_i = data[:, i].reshape([-1, 1])\n",
    "        BasisLib_i = BasisLib[:,i]\n",
    "\n",
    "        X_i = []\n",
    "        for k in range(Basis_num):\n",
    "            BasisK_i = BasisLib_i[k]\n",
    "\n",
    "            for j in range(LagOrder):\n",
    "                X_ij = data[:, i-j-1].reshape([-1, 1])\n",
    "                X_i += [ X_ij*BasisK_i ]\n",
    "\n",
    "        X_i = np.concatenate(X_i, axis=0)\n",
    "\n",
    "        Y.append(Y_i)\n",
    "        X.append(X_i)\n",
    "\n",
    "    Y = np.concatenate(Y, axis=1)\n",
    "    X = np.concatenate(X, axis=1)\n",
    "\n",
    "    XtX_inv = np.linalg.inv(X @ X.T)  # Regularization to avoid singular matrix\n",
    "\n",
    "    # ======= Solve the least squares problem to find coefficients =======\n",
    "    # model = Ridge(alpha=1e-4)  # or cross-validate for alpha\n",
    "    # model.fit(X.T, Y.T)\n",
    "    # Coefs = model.coef_\n",
    "\n",
    "    Coefs = np.linalg.lstsq(X.T, Y.T, rcond=None)[0].T\n",
    "    \n",
    "    Coefs_byBasis = np.split(Coefs, Basis_num, axis=1)   # split coefficients by basis function\n",
    "\n",
    "    # ======= Estimate time-varying MVAR coefficients =======\n",
    "    A_est = []\n",
    "    t_est = []\n",
    "    for i in range(LagOrder, n):\n",
    "        A_est_i = np.zeros([m, m*LagOrder])\n",
    "\n",
    "        for k in range(Basis_num):\n",
    "            BasisLib_ki = BasisLib[k, i]\n",
    "            A_est_i += Coefs_byBasis[k] * BasisLib_ki\n",
    "\n",
    "        A_est.append(np.reshape(A_est_i, [m,m,LagOrder], order='F'))\n",
    "        t_est.append(time[i])\n",
    "\n",
    "\n",
    "    return A_est, t_est\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115534f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis_Legendre(t, degree):\n",
    "    \"\"\"\n",
    "    Generate a Legendre polynomial basis function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, shape (n,)\n",
    "        Time points at which to evaluate the basis function.\n",
    "    degree : int\n",
    "        Degree of the Legendre polynomial.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    basis : ndarray, shape (n,)\n",
    "        Evaluated Legendre polynomial at the given time points, rescaled to [-1, 1].\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    t_rescaled = 2 * (t - t.min()) / (t.max() - t.min()) - 1\n",
    "    basis_func = np.polynomial.legendre.Legendre.basis(deg=degree)\n",
    "    basis = basis_func(t_rescaled)\n",
    "    return basis\n",
    "\n",
    "\n",
    "def basis_Walsh(t, k):\n",
    "    \"\"\"\n",
    "    Generate the k-th Walsh function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, shape (n,)\n",
    "        Time points at which to evaluate the Walsh function.\n",
    "    k : int\n",
    "        Order of the Walsh function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    basis : ndarray, shape (n,)\n",
    "        Evaluated Walsh function at the given time points, scaled to [0, 1].\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import scipy as sp\n",
    "\n",
    "    def sequency_order(H):\n",
    "        return sorted(range(H.shape[0]), key=lambda i: np.sum(H[i][1:] != H[i][:-1]))\n",
    "\n",
    "    t_rescaled = (t - t.min()) / (t.max() - t.min())\n",
    "    n = int(np.ceil(np.log2(np.max([k+1, 1]))))\n",
    "    m = 2**n\n",
    "    H = sp.linalg.hadamard(m)\n",
    "    order = sequency_order(H)\n",
    "    basis = H[order[k]]\n",
    "    step_idx = np.floor(t_rescaled * m).astype(int)\n",
    "    step_idx = np.clip(step_idx, 0, m-1)\n",
    "    return basis[step_idx]\n",
    "\n",
    "\n",
    "def basis_Chebyshev(t, degree):\n",
    "    \"\"\"\n",
    "    Generate a Chebyshev polynomial basis function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, shape (n,)\n",
    "        Time points at which to evaluate the Chebyshev polynomial.\n",
    "    degree : int\n",
    "        Degree of the Chebyshev polynomial.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    basis : ndarray, shape (n,)\n",
    "        Evaluated Chebyshev polynomial at the given time points, rescaled to [-1, 1].\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    t_rescaled = 2 * (t - t.min()) / (t.max() - t.min()) - 1\n",
    "    basis = np.polynomial.chebyshev.chebvander(t_rescaled, degree)[:, degree]\n",
    "    return basis\n",
    "\n",
    "\n",
    "def basis_Fourier_Sin(t, order):\n",
    "    \"\"\"\n",
    "    Generate a Fourier sine basis function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, shape (n,)\n",
    "        Time points at which to evaluate the sine basis function.\n",
    "    order : int\n",
    "        Order of the sine function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    basis : ndarray, shape (n,)\n",
    "        Evaluated Fourier sine function at the given time points, scaled to [0, 1].\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    t_rescaled = (t - t.min()) / (t.max() - t.min())\n",
    "    basis = np.sin(2 * np.pi * (order + 1) * t_rescaled)\n",
    "    return basis\n",
    "\n",
    "\n",
    "def basis_Fourier_Cos(t, order):\n",
    "    \"\"\"\n",
    "    Generate a Fourier cosine basis function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, shape (n,)\n",
    "        Time points at which to evaluate the cosine basis function.\n",
    "    order : int\n",
    "        Order of the cosine function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    basis : ndarray, shape (n,)\n",
    "        Evaluated Fourier cosine function at the given time points, scaled to [0, 1].\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    t_rescaled = (t - t.min()) / (t.max() - t.min())\n",
    "    basis = np.cos(2 * np.pi * (order + 1) * t_rescaled)\n",
    "    return basis\n",
    "\n",
    "\n",
    "def basis_Wavelet_Morlet(t, scale=1, shift=0, w0=5.0):\n",
    "    \"\"\"\n",
    "    Generate a Morlet wavelet basis function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, shape (n,)\n",
    "        Time points at which to evaluate the Morlet wavelet.\n",
    "    scale : float, optional\n",
    "        Scale of the wavelet. Default is 1.\n",
    "    shift : float, optional\n",
    "        Shift of the wavelet along time. Default is 0.\n",
    "    w0 : float, optional\n",
    "        Central frequency of the Morlet wavelet. Default is 5.0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Psi : ndarray, shape (n,)\n",
    "        Evaluated Morlet wavelet at the given time points.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    t_rescaled = (t - shift) / scale\n",
    "    norm = np.pi**(-0.25) / np.sqrt(scale)\n",
    "    gaussian = np.exp(-0.5 * t_rescaled**2)\n",
    "    sinusoid = np.cos(w0 * t_rescaled)\n",
    "    Psi = norm * gaussian * sinusoid\n",
    "    return Psi\n",
    "\n",
    "\n",
    "def basis_Wavelet_Ricker(t, scale=1, shift=0):\n",
    "    \"\"\"\n",
    "    Generate a Ricker (Mexican Hat) wavelet basis function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, shape (n,)\n",
    "        Time points at which to evaluate the Ricker wavelet.\n",
    "    scale : float, optional\n",
    "        Scale of the wavelet. Default is 1.\n",
    "    shift : float, optional\n",
    "        Shift of the wavelet along time. Default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Psi : ndarray, shape (n,)\n",
    "        Evaluated Ricker wavelet at the given time points.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    t_rescaled = (t - shift) / scale\n",
    "    norm = 2 / (np.sqrt(3 * scale) * np.pi**0.25)\n",
    "    Psi = norm * (1 - t_rescaled**2) * np.exp(-0.5 * t_rescaled**2)\n",
    "    return Psi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eea3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_TV_matrix(A, t, pValues=None, shareAxes=None):\n",
    "    \"\"\"\n",
    "    Plot time-varying MVAR or similar matrices across all variables and lags.\n",
    "\n",
    "    This function visualizes each element of a time-varying matrix A over time.\n",
    "    Optionally, it highlights significant entries based on p-values. Multiple\n",
    "    lags are plotted in separate figures, and axis sharing can be customized.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : list of ndarray, each shape (m, m, lags)\n",
    "        Time-varying matrices to plot. Each element in the list corresponds to a\n",
    "        specific time point. If 2D matrices are provided, they are assumed to have\n",
    "        a single lag and reshaped automatically.\n",
    "    t : list or ndarray, shape (n,)\n",
    "        Time points corresponding to each A matrix.\n",
    "    pValues : list of ndarray, optional\n",
    "        Corresponding p-values for each element in A. Same structure as A.\n",
    "        Significant values (p < 0.03) are highlighted as red dots on the plots.\n",
    "    shareAxes : str or None, optional\n",
    "        Axis sharing option for subplots:\n",
    "        - 'x': share x-axis\n",
    "        - 'y': share y-axis\n",
    "        - 'both': share both axes\n",
    "        - None: no axis sharing (default)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays one figure per lag, with subplots for each matrix element.\n",
    "        Significant values are overlaid as red scatter points when `pValues` is provided.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    pValue_critical = 0.03\n",
    "\n",
    "    time_points = len(t)\n",
    "    for i in range(time_points):\n",
    "        if A[i].ndim == 2: A[i] = A[i][:, :, np.newaxis]\n",
    "\n",
    "    m, _, Lag = A[0].shape\n",
    "\n",
    "    for p in range(Lag):\n",
    "        if shareAxes is None:\n",
    "            fig, ax = plt.subplots(m, m, figsize=(2*m, 2*m), sharex=False, sharey=False)\n",
    "        elif shareAxes == 'x':\n",
    "            fig, ax = plt.subplots(m, m, figsize=(2*m, 2*m), sharex=True, sharey=False)\n",
    "        elif shareAxes == 'y':\n",
    "            fig, ax = plt.subplots(m, m, figsize=(2*m, 2*m), sharex=False, sharey=True)\n",
    "        elif shareAxes == 'both':\n",
    "            fig, ax = plt.subplots(m, m, figsize=(2*m, 2*m), sharex=True, sharey=True)\n",
    "\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "            # for j in range(i+1):\n",
    "                A_arrays = [A[w][i, j, p] for w in range(time_points)]\n",
    "                ax[i, j].plot(t, A_arrays)\n",
    "                ax[i, j].grid()\n",
    "                # ax[i, j].set_title(f\"A[{i+1}, {j+1}]\")\n",
    "\n",
    "                if pValues is not None:\n",
    "                    w_plot = [t[w] for w in range(time_points) if pValues[w][i,j,p]<pValue_critical]\n",
    "                    pValue_plot = [A[w][i,j,p] for w in range(time_points) if pValues[w][i,j,p]<pValue_critical]\n",
    "                    ax[i, j].scatter(w_plot, pValue_plot, color='r', alpha=0.2, label='p-values')\n",
    "                    # ax[i, j].legend()\n",
    "\n",
    "        fig.suptitle(f\"A[lag={p+1}]\")\n",
    "        if pValues is not None:\n",
    "            fig.suptitle(f\"A[lag={p+1}] (red dots: p-values < 0.03)\")\n",
    "\n",
    "        # plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
